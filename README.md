# uber_highload

## 1. Целевая аудитория
- 91 млн. активных пользователей
- 4 млн. водителей-партнеров
- 14 млн. поездок ежедневно
- Основная аудитория сервиса находится в северной Америке и Европе

## 2. Расчет нагрузки

В городе Нью-Йорке, где очень много пользуются такси, в начале 2020 года, в день совершалось около 520к поездок, при 69к водителей на линии https://www.businessofapps.com/data/uber-statistics/. Возьмем эту статистику и рассчитаем, сколько примерно водителей на линии в мире одновременно:
**14 000к / 520к * 69к = 1 858к**

Водители будут каждые 3 секунды отсылать свои координаты.
1 858 000 / 3 = 619 334 rps.
Водитель посылает свой id (4 байта), широту (8 байт), долготу (8 байт).
Каждый 3 секунды, водители будут присылать 36Мб данных о своем местоположении. В день будет перадавься 1Тб данных с местоположением водителей.
Для экономии трафика водителей данные будем передавать по UDP, т.к. данные не критичны и мы можем их терять.

Расчитаем пиковую нагрузку, которую создают клиенты. 14 000 000 / 86 400 * 3 = 486 rps.
На запрос пользователя, будем выдавать максимум 5 ближайших машин.

|         | Кол-во RPS|
|---------| ----------|
|Водители | 619к      |
|Клиенты  | 500       |

## 3. Логическая схема базы данных
![Снимок экрана 2021-06-04 в 13 58 50](https://user-images.githubusercontent.com/43621139/120799954-11177800-c548-11eb-8e82-e0532a16e6f9.png)


## 4. Физическая схема базы данных
- для хранения информации о клиентах, водителях, поездках будем использовать Postgres
- для хранения геолокации водителей будем использовать Postgres вместе с расширением PostGIS
- для сессий водителей и клиентов возьмем Redis

Для базы данных с геопозицией будем использовать шардирование. Шардирование базы данных будем делать по геолокации. Для больших мегаполисов выделим 1 или более шардов. Выбор в какой шард делать запрос будет делаться на уровне сервиса геолокации на основании геолокации клиента.

Postgres, работая на 1 ядре, сможет выполнить 500 запросов в секунду. Соответственно на 32 ядерном процессоре, можно выполнять около 16к вставок. Для того, чтобы выдержать нагрузку в 619к записей, 200к из которых приходится на США, а остальные 400 на Европу, сделаем 20 шардов для США, которые смогу выдежать 320к вставок и 40 шардов для Европы, которые смогу выдержать 640к вставок.

Также для надеждность воспользуемся репликацией. Использовать будем схему мастер - реплика. На каждый шард будет отдельный мастер и 2 реплики. Читать будем из реплик, в случае, если мастер упал, одна из реплик становится мастером.

Для одного кортежа необходимо 44 байт. Для хранения геолокации всех 4 млн водителей нужно 168 Мб, что несущественно.

Базу для хранения информации о поездках также разобьем на 60 шардов, 20 для США и 40 для Европы. Этого будет достаточно, потому что кол-во вставок в нее будет меньше чем в базу геолокации, из-за того, что вставки делаются только при поездке с клиентом. Шардировать базу данных будем по id поездки.
Когда водитель будет исполнять заказ, будет сохранять маршрут всей поездки. Допустим, средняя поездка длится 15 минут, тогда для хранения маршрута одной поездки, нам понадобится 15 * 60 / 3 * (4 + 32 + 8) = 13 200 байт. Для хранения маршрутов за 1 день понадобится 172 Гб. У каждого шарда будет 2 реплики, поэтому в день на хранение маршрутов будет уходить 516 Гб.

Выбор в какой шард делать запрос будет делаться на уровне "Сервиса для работы с заказами" в зависимости от id заказа.

|     База данных     |   qps  |  Добавляется данных в день  | кол-во шардов |
|---------------------| -------|-----------------------------|---------------|
| Postgres, геолокация| 619к   | 0 Гб                        | 60            |
| Postgres, заказы    | < 619к | 172 Гб                      | 60            |

![Снимок экрана 2021-06-04 в 13 58 50 2](https://user-images.githubusercontent.com/43621139/120800109-3e642600-c548-11eb-9f12-85726caf2d3c.png)

## 5. Выбор технологий
В качестве языка для backend разработки выберем Go. Это компилируемый, статически типизуермый язык. Он достаточно производительный и потребляет адекватное количество ресурсов. Он прост в изучении, что позволит нанимать программистов с опытом работы на других языках. Упор будем делать на мобильные приложения, поэтому для их разработки выберем языки Swift и Kotlin. Для организации очередей будем использовать kafka.

## 6. Схема проекта
![Снимок экрана 2021-05-31 в 22 35 37](https://user-images.githubusercontent.com/43621139/120234401-8ccfa700-c260-11eb-874d-9dfc61923b60.png)

## 7. Выбор оборудования
1) Выбор оборудования для балансировщиков нагрузки.
Нагрузка на балансировщики составляет 619к запросов в секунду. Исходя из тестов производительности https://www.nginx.com/wp-content/uploads/2014/07/NGINX-SSL-Performance.pdf, Nginx с 8 ядрами, может выдержать около 2к с учетом SSL терминации, для надежности, возьмем 1.5к. Соответственно, с 16 ядрами, мы можем расчитывать на 3к rps. Для того, чтобы выдержать 619к запросов в секунду, нам понадобится 210 сервером с 16 ядрами. Для надежности. увеличим эту цифру в 2 раза.

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 16        | 16         |           | 420       |

2) Для kafka достаточно будет по 3 сервера на каждом континенте https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 6         | 32         | 50        | 6         |

3) Сервис геолокаций

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 32        | 32         | 50        | 30        |

4) Сервис для работы с заказами

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 32        | 32         | 50        | 30        |

5) Основной бекэнд

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 32        | 32         | 50        | 4         |

6) Postgres с координатами водителей. Как я расчитывал ранее, 1 Postgres, работающий на 32 ядрах, может выдержать вставку 16к записей. Чтобы выдержать 619к записей с запасом, нам понадобится 60 мастеров и 120 реплик.

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 32        | 32         | 5         | 180       |

7) Postgres с заказами и маршрутами. Аналогично базе с координатами водителей, понадобится 60 мастеров и 120 реплик. Т.к. в день данные о маршрутах увеличиваются на 516 Гб, то для того, чтобы места хватило на 4+ года, необходимы диске объемом 5 Тб на каждой машине.

| CPU, Ядра |  RAM, Гб   |  SSD, Гб  |число машин|
|-----------| -----------|-----------|-----------|
| 32        | 32         | 5000      | 180       |
